Description about the project work:  
The Air Canvas project aims to create a virtual canvas where users can draw in the air using 
their hand movements. By leveraging computer vision techniques, the project tracks the user's 
hand movements and translates these into drawing commands, allowing for real-time 
interaction without the need for physical contact with a drawing surface. 
Key Components 
1. Hand Detection and Tracking: The system uses a camera to capture video frames and 
detect the user's hand in real-time. 
2. Gesture Recognition: Specific hand gestures are recognized to distinguish between 
different drawing actions (e.g., drawing, erasing). 
3. Drawing on Canvas: The detected hand movements are translated into drawing 
commands on a virtual canvas. 
Algorithm:  
1. Start reading the frames and convert the captured frames to HSV color space (Easy for 
color detection).  
2. Prepare the canvas frame and put the respective ink buttons on it.  
3. Adjust the track bar values for finding the mask of the colored marker.  
4. Preprocess the mask with morphological operations (Eroding and dilation).  
5. Detect the contours, find the center coordinates of largest contour and keep storing them 
in the array for successive frames (Arrays for drawing points on canvas).  
Brief description about functions, methods, modules, libraries, etc. used: 
Libraries and Modules: 
1. OpenCV (`cv2`):  
An open-source computer vision and machine learning software library. Provides a common 
infrastructure for computer vision applications. 
Functions Used: 
• `cv2.VideoCapture()`: Captures video from a camera. 
• `cv2.cvtColor()`: Converts images from one color space to another. 
• `cv2.imshow()`: Displays an image in a window. 
• `cv2.waitKey()`: Waits for a key event. 
• `cv2.circle()`: Draws a circle on an image. 
• `cv2.add()`: Adds two images.
  2. Mediapipe (mediapipe): 
A cross-platform library developed by Google for building multimodal (e.g., video, audio, 
etc.) applied machine learning pipelines. 
Modules Used: 
mediapipe.solutions.hands : Provides tools for hand detection and   tracking. 
Classes and Methods: 
• mp_hands.Hands(): Initializes the hand tracking module. 
• hands.process() : Processes an image and returns hand landmarks. 
• mp_drawing.draw_landmarks(): Draws hand landmarks and connections on an image. 
3. NumPy (`numpy`): 
A fundamental package for scientific computing with Python. It provides support for arrays, 
matrices, and many mathematical functions. 
Functions Used: 
np.zeros(): Creates a new array of given shape and type, filled with    zeros. 
Functions and Methods 
1. Video Capture and Processing: 
• cv2.VideoCapture(0): Opens the default camera for capturing video frames. 
• cap.read(): Reads a frame from the video capture object. 
• cv2.cvtColor(frame,cv2.COLOR_BGR2RGB): Converts the color space of the 
captured frame from BGR to RGB, as Mediapipe expects RGB images. 
2. Hand Detection and Tracking: 
• mp_hands.Hands(): Initializes the hand tracking model with default parameters. 
• hands.process(frame_rgb): Processes the RGB frame to detect hand landmarks. 
mp_drawing.draw_landmarks(frame,hand_landmarks,mp_hands.HAND_CON
 NECTIONS): Draws the detected hand landmarks and connections on the frame for 
visualization.
  3. Drawing on Canvas : 
• np.zeros((480, 640, 3), dtype="uint8"): Creates a blank canvas of the same size as 
the video frame. 
• cv2.circle(canvas, (x, y), 5, (255, 0, 0), -1): Draws a circle on the canvas at the specified 
coordinates `(x, y)`, simulating the drawing action. 
• cv2.add(frame, canvas): Overlays the canvas on the current video frame to show the 
drawing in real-time. 
4. Displaying the Video: 
• cv2.imshow('Air Canvas', frame): Displays the current frame in a window titled 'Air 
Canvas'. 
• cv2.waitKey(1): Waits for 1 millisecond for a key event. The loop continues until the 
ESC key (with ASCII code 27) is pressed. 
5. Cleanup: 
• cap.release(): Releases the video capture object. 
• cv2.destroyAllWindows(): Closes all OpenCV windows. 
